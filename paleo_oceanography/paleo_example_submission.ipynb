{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# Example for classifying forams in paleo oceanography Kaggle competition.\n",
    "# Author: Peter Sadowski\n",
    "# Date: Nov 2 2024\n",
    "# This runs on google colab TPU, and achieves 57% accuracy on public leaderboard."
   ],
   "metadata": {
    "id": "WRg3UQ16Xwj9",
    "ExecuteTime": {
     "end_time": "2024-11-13T00:52:04.952267Z",
     "start_time": "2024-11-13T00:52:04.950601Z"
    }
   },
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "# # Download data files from public google drive.\n",
    "# # Takes ~1min\n",
    "# !pip install --upgrade --no-cache-dir gdown\n",
    "# import gdown\n",
    "# \n",
    "# file_ids = {'train.zip': '1mm2tEB05wQwNHP0SySTCp1-BL6G1IHf0',\n",
    "#             'test.zip': '1Cf-yAfSt706w10p5Dij7ppFLo6Se8Ej7',\n",
    "#             'train.csv': '1NAd3UPTWWxmXdJ9N_Mr3GWgMmO_Aojnn',\n",
    "#             'test.csv': '1Koi9hpUuUwn1swel9QLsEOr_MZKX2LOg',\n",
    "#             }\n",
    "# \n",
    "# for output, file_id in file_ids.items():\n",
    "#   url=f\"https://drive.google.com/uc?id={file_id}\"\n",
    "#   gdown.download(url, output, quiet=False)\n",
    "# \n",
    "# !unzip -q train.zip\n",
    "# !unzip -q test.zip\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xlghoI3imA_w",
    "outputId": "b1548b5f-9b7c-476d-dfd3-85a51a953773",
    "ExecuteTime": {
     "end_time": "2024-11-13T00:52:04.994977Z",
     "start_time": "2024-11-13T00:52:04.993518Z"
    }
   },
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kLRcpahCiuWE",
    "ExecuteTime": {
     "end_time": "2024-11-13T00:52:05.044198Z",
     "start_time": "2024-11-13T00:52:05.036415Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "# https://stackoverflow.com/questions/72371859/attributeerror-module-collections-has-no-attribute-iterable\n",
    "import collections\n",
    "collections.Iterable = collections.abc.Iterable\n",
    "\n",
    "class ImageCSVDataset(Dataset):\n",
    "    def __init__(self, image_dir, csv_file, transform=None, test_set=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image_dir (string): Directory with all the images.\n",
    "            csv_file (string): Path to the csv file with labels.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "\n",
    "        \"\"\"\n",
    "        self.image_dir = image_dir\n",
    "        self.labels = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.test_set = test_set\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = self.labels.iloc[idx]['filename']  # Assuming image name is in the first column\n",
    "        image = Image.open(f\"{self.image_dir}/{img_name}\").convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.test_set:\n",
    "          return image\n",
    "\n",
    "        label = self.labels.iloc[idx]['label']  # Assuming label is in the second column\n",
    "        return image, label\n",
    "\n",
    "# Define dataset and data loader.\n",
    "image_dir = 'train/'\n",
    "csv_file = 'train.csv'\n",
    "image_dir_test = 'test/'\n",
    "csv_file_test = 'test.csv'\n",
    "\n",
    "# Define transformations (optional)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images\n",
    "    transforms.ToTensor(),          # Convert to PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                         std=[0.225, 0.225, 0.225])  # Normalize\n",
    "])\n",
    "\n",
    "dataset = ImageCSVDataset(image_dir=image_dir, csv_file=csv_file, transform=transform)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "# Train a NN from scratch.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the CNN model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32 * 56 * 56, 128),  # Adjust input size based on image dimensions\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model, optimizer, and loss function\n",
    "#num_classes = len(dataset.labels['label'].unique())  # Get number of unique classes from the dataset\n",
    "num_classes = dataset.labels['label'].max()+1  # Get number of unique classes from the dataset\n",
    "model = SimpleCNN(num_classes)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 1\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if i % 100 == 99:  # Print every 100 mini-batches\n",
    "            print(f\"[{epoch + 1}, {i + 1}] loss: {running_loss / 100:.3f}\")\n",
    "            running_loss = 0.0\n",
    "\n",
    "print(\"Finished Training\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vr_uQVLDj4Wn",
    "outputId": "c9bcabfc-f502-4526-8492-1eacd6fcdfb1",
    "ExecuteTime": {
     "end_time": "2024-11-13T00:52:15.900692Z",
     "start_time": "2024-11-13T00:52:05.083866Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/dev/PycharmProjects/ics637/venv/lib/python3.13/site-packages/torchvision/transforms/functional.py:63: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 100] loss: 2.180\n",
      "[1, 200] loss: 1.521\n",
      "Finished Training\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "# Use model to make predictions.\n",
    "\n",
    "# Create test dataloader that doesn't have labels.\n",
    "dataset_test = ImageCSVDataset(image_dir=image_dir_test, csv_file=csv_file_test,\n",
    "                               transform=transform, test_set=True)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=32, shuffle=False)\n",
    "\n",
    "predictions = []\n",
    "for i, data in enumerate(dataloader_test, 0):\n",
    "    inputs = data.to(device)\n",
    "    outputs = model(inputs)\n",
    "    predictions.append(outputs.argmax(axis=1).detach().cpu().numpy())\n",
    "predictions = np.concatenate(predictions)\n",
    "\n",
    "# Write predictions to a submission file.\n",
    "df_predictions = pd.read_csv(csv_file_test)\n",
    "df_predictions['predictions'] = predictions\n",
    "# df_predictions[['id', 'predictions']].to_csv('submission.csv', index=False)\n",
    "\n",
    "display(df_predictions)\n"
   ],
   "metadata": {
    "id": "k6JpilrkPBlH",
    "ExecuteTime": {
     "end_time": "2024-11-13T00:56:38.775661Z",
     "start_time": "2024-11-13T00:56:37.149956Z"
    }
   },
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "# Fine tune a pre-trained model\n",
    "from torchvision import models\n",
    "\n",
    "# Load a pre-trained model\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Modify the final fully connected layer\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, num_classes)  # Replace with your number of classes\n",
    "\n",
    "# Freeze early layers (optional)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze later layers (optional)\n",
    "for layer in list(model.children())[-3:]:  # Unfreeze last 3 layers\n",
    "    for param in layer.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "# 4. Define optimizer and loss function\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 5. Create DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# 6. Train the model (similar to previous example)\n",
    "num_epochs = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if i % 100 == 99:  # Print every 100 mini-batches\n",
    "            print(f\"[{epoch + 1}, {i + 1}] loss: {running_loss / 100:.3f}\")\n",
    "            running_loss = 0.0"
   ],
   "metadata": {
    "id": "OVmyVI-Tkimh",
    "ExecuteTime": {
     "end_time": "2024-11-13T00:59:37.176163Z",
     "start_time": "2024-11-13T00:57:25.491607Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /home/echung32/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n",
      "100%|██████████| 44.7M/44.7M [00:01<00:00, 30.9MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 100] loss: 1.032\n",
      "[1, 200] loss: 0.786\n",
      "[2, 100] loss: 0.549\n",
      "[2, 200] loss: 0.552\n",
      "[3, 100] loss: 0.402\n",
      "[3, 200] loss: 0.388\n",
      "[4, 100] loss: 0.245\n",
      "[4, 200] loss: 0.278\n",
      "[5, 100] loss: 0.178\n",
      "[5, 200] loss: 0.200\n",
      "[6, 100] loss: 0.115\n",
      "[6, 200] loss: 0.110\n",
      "[7, 100] loss: 0.088\n",
      "[7, 200] loss: 0.098\n",
      "[8, 100] loss: 0.060\n",
      "[8, 200] loss: 0.058\n",
      "[9, 100] loss: 0.042\n",
      "[9, 200] loss: 0.061\n",
      "[10, 100] loss: 0.039\n",
      "[10, 200] loss: 0.055\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T00:59:47.935187Z",
     "start_time": "2024-11-13T00:59:45.180758Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Use model to make predictions.\n",
    "\n",
    "# Create test dataloader that doesn't have labels.\n",
    "dataset_test = ImageCSVDataset(image_dir=image_dir_test, csv_file=csv_file_test,\n",
    "                               transform=transform, test_set=True)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=32, shuffle=False)\n",
    "\n",
    "predictions = []\n",
    "for i, data in enumerate(dataloader_test, 0):\n",
    "    inputs = data.to(device)\n",
    "    outputs = model(inputs)\n",
    "    predictions.append(outputs.argmax(axis=1).detach().cpu().numpy())\n",
    "predictions = np.concatenate(predictions)\n",
    "\n",
    "# Write predictions to a submission file.\n",
    "df_predictions = pd.read_csv(csv_file_test)\n",
    "df_predictions['predictions'] = predictions\n",
    "# df_predictions[['id', 'predictions']].to_csv('submission.csv', index=False)\n",
    "\n",
    "display(df_predictions)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        id                   filename  predictions\n",
       "0        0  MV1012-BC-12_obj00007.jpg            1\n",
       "1        1  MV1012-BC-12_obj00009.jpg            3\n",
       "2        2  MV1012-BC-12_obj00011.jpg            1\n",
       "3        3  MV1012-BC-12_obj00012.jpg            3\n",
       "4        4  MV1012-BC-12_obj00013.jpg            5\n",
       "...    ...                        ...          ...\n",
       "2169  2169   MV1012-BC-8_obj01887.jpg            0\n",
       "2170  2170   MV1012-BC-8_obj01892.jpg            0\n",
       "2171  2171   MV1012-BC-8_obj01893.jpg            0\n",
       "2172  2172   MV1012-BC-8_obj01899.jpg            1\n",
       "2173  2173   MV1012-BC-8_obj01907.jpg            3\n",
       "\n",
       "[2174 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>filename</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MV1012-BC-12_obj00007.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>MV1012-BC-12_obj00009.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>MV1012-BC-12_obj00011.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>MV1012-BC-12_obj00012.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>MV1012-BC-12_obj00013.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2169</th>\n",
       "      <td>2169</td>\n",
       "      <td>MV1012-BC-8_obj01887.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2170</th>\n",
       "      <td>2170</td>\n",
       "      <td>MV1012-BC-8_obj01892.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2171</th>\n",
       "      <td>2171</td>\n",
       "      <td>MV1012-BC-8_obj01893.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2172</th>\n",
       "      <td>2172</td>\n",
       "      <td>MV1012-BC-8_obj01899.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2173</th>\n",
       "      <td>2173</td>\n",
       "      <td>MV1012-BC-8_obj01907.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2174 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 16
  }
 ]
}

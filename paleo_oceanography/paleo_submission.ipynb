{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T09:36:54.326229Z",
     "start_time": "2024-11-13T09:36:54.323177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from jupyter_server.transutils import trans\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "# https://stackoverflow.com/questions/72371859/attributeerror-module-collections-has-no-attribute-iterable\n",
    "import collections\n",
    "collections.Iterable = collections.abc.Iterable"
   ],
   "id": "dc7d69beac19675a",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# import the data",
   "id": "c5a4ca9eb92f565"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-13T09:18:17.313682Z",
     "start_time": "2024-11-13T09:18:17.309454Z"
    }
   },
   "source": [
    "class ImageCSVDataset(Dataset):\n",
    "    def __init__(self, image_dir, csv_file, transform=None, test_set=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image_dir (string): Directory with all the images.\n",
    "            csv_file (string): Path to the csv file with labels.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "\n",
    "        \"\"\"\n",
    "        self.image_dir = image_dir\n",
    "        self.labels = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.test_set = test_set\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = self.labels.iloc[idx]['filename']  # Assuming image name is in the first column\n",
    "        image = Image.open(f\"{self.image_dir}/{img_name}\").convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.test_set:\n",
    "          return image\n",
    "\n",
    "        label = self.labels.iloc[idx]['label']  # Assuming label is in the second column\n",
    "        return image, label\n",
    "\n",
    "# Define dataset and data loader.\n",
    "image_dir = 'train/'\n",
    "csv_file = 'train.csv'\n",
    "image_dir_test = 'test/'\n",
    "csv_file_test = 'test.csv'"
   ],
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T09:18:17.355402Z",
     "start_time": "2024-11-13T09:18:17.353571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define transformations (optional)\n",
    "# https://pytorch.org/vision/main/transforms.html\n",
    "# https://www.kaggle.com/datasets/abhinavnayak/catsvdogs-transformed\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images\n",
    "    # transforms.RandomResizedCrop((224, 224)),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),          # Convert to PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                         std=[0.225, 0.225, 0.225])  # Normalize\n",
    "])"
   ],
   "id": "90db9e54f84468a3",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T09:42:49.281975Z",
     "start_time": "2024-11-13T09:42:49.276729Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = ImageCSVDataset(image_dir=image_dir, csv_file=csv_file, transform=transform)\n",
    "\n",
    "dataset_size = len(dataset)\n",
    "train_size = int(0.8 * dataset_size)\n",
    "val_size = dataset_size - train_size\n",
    "print(dataset_size, train_size, val_size)\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoaders for training and validation sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ],
   "id": "d63c8b1a2ab4f933",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8653 6922 1731\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# fine tune pre-trained model\n",
    "\n",
    "https://github.com/pytorch/examples/blob/main/imagenet/main.py"
   ],
   "id": "17eabd2916850ee7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T09:29:10.618538Z",
     "start_time": "2024-11-13T09:18:17.443150Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load a pre-trained model\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# Modify the final fully connected layer\n",
    "num_classes = dataset.labels['label'].max() + 1 \n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, num_classes)  # Replace with your number of classes\n",
    "\n",
    "# Freeze early layers (optional)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze later layers (optional)\n",
    "for layer in list(model.children())[-3:]:  # Unfreeze last 3 layers\n",
    "    for param in layer.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "# 4. Define optimizer and loss function\n",
    "# optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n",
    "optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001, weight_decay=1e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 6. Train the model (similar to previous example)\n",
    "num_epochs = 20\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if i % 100 == 99:  # Print every 100 mini-batches\n",
    "            print(f\"[{epoch + 1}, {i + 1}] loss: {running_loss / 100:.3f}\")\n",
    "            running_loss = 0.0"
   ],
   "id": "db660f8f14236798",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 100] loss: 1.201\n",
      "[1, 200] loss: 0.900\n",
      "[2, 100] loss: 0.739\n",
      "[2, 200] loss: 0.724\n",
      "[3, 100] loss: 0.629\n",
      "[3, 200] loss: 0.627\n",
      "[4, 100] loss: 0.559\n",
      "[4, 200] loss: 0.577\n",
      "[5, 100] loss: 0.525\n",
      "[5, 200] loss: 0.524\n",
      "[6, 100] loss: 0.466\n",
      "[6, 200] loss: 0.511\n",
      "[7, 100] loss: 0.475\n",
      "[7, 200] loss: 0.445\n",
      "[8, 100] loss: 0.433\n",
      "[8, 200] loss: 0.422\n",
      "[9, 100] loss: 0.392\n",
      "[9, 200] loss: 0.406\n",
      "[10, 100] loss: 0.379\n",
      "[10, 200] loss: 0.365\n",
      "[11, 100] loss: 0.337\n",
      "[11, 200] loss: 0.367\n",
      "[12, 100] loss: 0.327\n",
      "[12, 200] loss: 0.341\n",
      "[13, 100] loss: 0.304\n",
      "[13, 200] loss: 0.316\n",
      "[14, 100] loss: 0.309\n",
      "[14, 200] loss: 0.280\n",
      "[15, 100] loss: 0.263\n",
      "[15, 200] loss: 0.260\n",
      "[16, 100] loss: 0.262\n",
      "[16, 200] loss: 0.276\n",
      "[17, 100] loss: 0.245\n",
      "[17, 200] loss: 0.242\n",
      "[18, 100] loss: 0.229\n",
      "[18, 200] loss: 0.218\n",
      "[19, 100] loss: 0.208\n",
      "[19, 200] loss: 0.180\n",
      "[20, 100] loss: 0.179\n",
      "[20, 200] loss: 0.193\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T09:29:16.944752Z",
     "start_time": "2024-11-13T09:29:10.641272Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Validation\n",
    "model.eval() # toggle evaluation mode\n",
    "val_loss = 0.0\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in val_loader:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        val_loss += loss.item()\n",
    "\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "model.train() # toggle back training mode\n",
    "\n",
    "# Calculate validation accuracy\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "print(f\"Validation Loss: {val_loss/len(val_loader):.4f}, Accuracy: {accuracy:.4f}\")"
   ],
   "id": "73f628630cc659f1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.7601, Accuracy: 0.8163\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T09:29:25.186494Z",
     "start_time": "2024-11-13T09:29:16.960015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Use model to make predictions.\n",
    "\n",
    "# Create test dataloader that doesn't have labels.\n",
    "dataset_test = ImageCSVDataset(image_dir=image_dir_test, csv_file=csv_file_test,\n",
    "                               transform=transform, test_set=True)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=32, shuffle=False)\n",
    "\n",
    "predictions = []\n",
    "for i, data in enumerate(dataloader_test, 0):\n",
    "    inputs = data.to(device)\n",
    "    outputs = model(inputs)\n",
    "    predictions.append(outputs.argmax(axis=1).detach().cpu().numpy())\n",
    "predictions = np.concatenate(predictions)\n",
    "\n",
    "# Write predictions to a submission file.\n",
    "df_predictions = pd.read_csv(csv_file_test)\n",
    "df_predictions['predictions'] = predictions\n",
    "df_predictions[['id', 'predictions']].to_csv('submission.csv', index=False)\n",
    "\n",
    "display(df_predictions)"
   ],
   "id": "104f63e5430eabac",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        id                   filename  predictions\n",
       "0        0  MV1012-BC-12_obj00007.jpg            1\n",
       "1        1  MV1012-BC-12_obj00009.jpg            3\n",
       "2        2  MV1012-BC-12_obj00011.jpg            1\n",
       "3        3  MV1012-BC-12_obj00012.jpg            3\n",
       "4        4  MV1012-BC-12_obj00013.jpg            5\n",
       "...    ...                        ...          ...\n",
       "2169  2169   MV1012-BC-8_obj01887.jpg            0\n",
       "2170  2170   MV1012-BC-8_obj01892.jpg            0\n",
       "2171  2171   MV1012-BC-8_obj01893.jpg            0\n",
       "2172  2172   MV1012-BC-8_obj01899.jpg            1\n",
       "2173  2173   MV1012-BC-8_obj01907.jpg            3\n",
       "\n",
       "[2174 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>filename</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MV1012-BC-12_obj00007.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>MV1012-BC-12_obj00009.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>MV1012-BC-12_obj00011.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>MV1012-BC-12_obj00012.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>MV1012-BC-12_obj00013.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2169</th>\n",
       "      <td>2169</td>\n",
       "      <td>MV1012-BC-8_obj01887.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2170</th>\n",
       "      <td>2170</td>\n",
       "      <td>MV1012-BC-8_obj01892.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2171</th>\n",
       "      <td>2171</td>\n",
       "      <td>MV1012-BC-8_obj01893.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2172</th>\n",
       "      <td>2172</td>\n",
       "      <td>MV1012-BC-8_obj01899.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2173</th>\n",
       "      <td>2173</td>\n",
       "      <td>MV1012-BC-8_obj01907.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2174 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 54
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
